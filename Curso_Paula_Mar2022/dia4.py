# -*- coding: utf-8 -*-
"""dia4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KzWhHVwhxC3emUqo0iUcNqPUftkBXr7s

# Curso Python

## Dia 4 - Plotes + Estatísticas
"""

# Commented out IPython magic to ensure Python compatibility.
# Importando as bibliotecas
import pandas as pd
import numpy as np
import datetime
import matplotlib.pyplot as plt
import statistics
import scipy.stats
# %matplotlib inline

# Abrindo o arquivo da boia de Santos

path = 'C:\\Users\\Paula\\Desktop\\curso-python\\'

arq_nome = 'boia_santos.txt'

dados = pd.read_csv(path+'dados\\'+arq_nome, sep=',', header = 0, index_col = 0, parse_dates = ['# Datetime'],
                   date_parser = lambda x: datetime.datetime.strptime(x ,"%Y-%m-%d %H:%M:%S"),
                   usecols = ['# Datetime','Wvht','Dpd','Mwd'])

dados.rename(columns={'Wvht': 'Hs', 'Dpd': 'Tp', 'Mwd': 'Dm'}, inplace = True)

# Completei para todo o período (início de 2011 ao fim de 2018)
datas = pd.date_range('2011-01-01 00:00:00', '2018-12-21 23:59:59', freq='H')

dados_c = dados.reindex(datas)

dados_c = dados_c.replace(-9999.00, np.nan)

print(dados_c)

"""##### 1. Dados NaN"""

# Vamos fazer um gráfico para verificar a quantidade de dados NaN de Hs por ano

# Hs

for i in range(2011, 2019):
    print(i)

# Lembrando
dados_c['Hs'].loc['2011']

nans_ano = []
for i in range(2011, 2019):
    hs_ano = dados_c['Hs'].loc[str(i)]
    print(hs_ano)

nans_ano = []
for i in range(2011, 2019):
    hs_ano = dados_c['Hs'].loc[str(i)]
    quant_nan = hs_ano.isnull().sum()
    print(quant_nan)

nans_ano = []
for i in range(2011, 2019):
    hs_ano = dados_c['Hs'].loc[str(i)]
    quant_nan = hs_ano.isnull().sum()
    print(i, quant_nan)

# Salvando os resultados dentro da lista vazia
nans_ano = []
for i in range(2011, 2019):
    hs_ano = dados_c['Hs'].loc[str(i)]
    quant_nan = hs_ano.isnull().sum()
    nans_ano.append(quant_nan)

print(nans_ano)

total_nans = np.sum(nans_ano)
print(total_nans)

## Loop para colocar o número de dados faltantes em termos percentuais

p_nans_anos = []

for i in nans_ano:
    percentual = (i*100)/total_nans
    print(percentual)

## Loop para colocar o número de dados faltantes em termos percentuais

p_nans_anos = []

for i in nans_ano:
    percentual = (i*100)/total_nans
    print(np.round(percentual,1))

    p_nans_anos.append(percentual)

# Plote
anos = ['2011','2012','2013','2014','2015', '2016', '2017', '2018']

plt.barh(anos, p_nans_anos, color = 'blue')

# Plote
anos = ['2011','2012','2013','2014','2015', '2016', '2017', '2018']

plt.figure(figsize=(10,7))

plt.barh(anos, p_nans_anos, color = 'blue', zorder = 500)
plt.xlabel("Percentual de dados faltantes")
plt.ylabel('Anos')
plt.title("Altura Significativa de Onda - Hs", fontweight='bold',fontsize=16)
plt.grid(zorder = 100)
plt.savefig(path+'figs\\Hs_nans.png')

# zorder, o número menor indica que a camada de grade vai ser plotada primeiro.

# Vamos fazer um gráfico para verificar a quantidade de dados NaN por variável, considerando todo o período

# Abrindo o arquivo da boia com todas as variáveis

# tiro o usecols

dados = pd.read_csv(path+'dados\\'+arq_nome, sep=',', header = 0, index_col = 0, parse_dates = ['# Datetime'],
                   date_parser = lambda x: datetime.datetime.strptime(x ,"%Y-%m-%d %H:%M:%S"))

dados.rename(columns={'Wvht': 'Hs', 'Dpd': 'Tp', 'Mwd': 'Dm'}, inplace = True)

datas = pd.date_range('2011-01-01 00:00:00', '2018-12-21 23:59:59', freq='H')

dados_t = dados.reindex(datas)

dados_t = dados_t.replace(-9999.00, np.nan)


print(dados)

print(dados_t.columns)

# Apago as colunas lat, lon, battery e bhead

df = dados_t.drop(columns=['Lat','Lon','Battery','bHead'], axis=1)

print(df)

df.isnull().sum().sum()

# Quantidade de dados nans por variável, considerando todo o período 
nan_total = df.isnull().sum()

print(nan_total)

df.columns

# Plote

plt.figure(figsize=(10,7))

plt.barh(df.columns, nan_total, color = 'magenta', zorder=5)
plt.xlabel("Quantidade de dados faltantes")
plt.ylabel('Variáveis')
plt.title("Variáveis meteoceanográficas da boia de Santos", fontweight='bold',fontsize=16)
plt.grid(zorder=0)
plt.savefig(path+'figs\\nans_variaveis_boia.png')

"""#### 2. Série temporal"""

# Plote dos dados de Hs ao longo de todo período

plt.plot(df.Hs)

# plote

plt.figure(figsize=(8,6))
plt.plot(df.Hs, 'o', color='indigo')
plt.grid()
plt.xlabel("Anos")
plt.ylabel("Hs (m)")
plt.title("Altura Significativa de Onda", fontweight='bold', fontsize=14)

# Inserindo o valor médio de Hs
mediahs = np.mean(df.Hs)
print(mediahs)

# plote

plt.figure(figsize=(8,6))
plt.plot(df.Hs, 'o', color='indigo')
plt.axhline(mediahs, color = 'red', linestyle='--')
plt.grid()
plt.xlabel("Anos")
plt.ylabel("Hs (m)")
plt.title("Altura Significativa de Onda", fontweight='bold', fontsize=14)
plt.savefig(path+'figs\\Hs.png')

## Pressão atmosférica
pmean = np.mean(df.Pres)
pmax = np.max(df.Pres)
pmin = np.min(df.Pres)

print(pmean, pmax, pmin)

# plote

# inserindo legenda

plt.figure(figsize=(8,6))
plt.plot(df.Pres, '-', color='darkcyan')
plt.axhline(pmax, color = 'red', linestyle='--', label="Máximo")
plt.axhline(pmean, color = 'orange', linestyle='-', label="Média")
plt.axhline(pmin, color = 'blue', linestyle='--', label="Mínimo")
plt.grid()
plt.xlabel("Anos")
plt.ylabel("Pressão (hPa)")
plt.title("Pressão Atmosférica", fontweight='bold', fontsize=14)
plt.legend(loc='upper left')
plt.savefig(path+'figs\\Patm.png')

"""#### 3. Preenchimento dos dados NaN """

print(dados_c)

# Separando o ano de 2012

dados12 = dados_c.loc['2012']

print(dados12)

plt.plot(dados12.Hs)

# Algumas vezes apenas substituir os dados nan por 1 valor só, faz sentido. Depende do caso.
# Substituindo NaN por 0
dados12_new = dados12.fillna(0)
print(dados12_new)

plt.plot(dados12_new.Hs)
plt.title('Preenchendo NaN com zero', fontweight='bold')

# Algumas vezes apenas substituir os dados nan por 1 valor só, faz sentido. Depende do caso.
# Substituindo NaN pela média

mediahs = dados12.Hs.mean()

dados12_new = dados12.fillna(mediahs)

plt.title('Preenchendo NaN com a média', fontweight='bold')
plt.plot(dados12_new.Hs)

"""#### 4. Interpolação
##### Link com os métodos https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html
"""

# Linear
linear = dados12.interpolate(method='linear')

plt.title('Interpolação linear', fontweight='bold')
plt.plot(linear.Hs)

# Pad
# Interpola usando o último valor válido e repete para os próximos
pad = dados12.interpolate(method='pad')

plt.title('Interpolação Pad', fontweight='bold')
plt.plot(pad.Hs)

# nearest
# Interpola usando o valor mais próximo
nearest = dados12.interpolate(method='nearest')
plt.title('Interpolação Nearest', fontweight='bold')
plt.plot(nearest.Hs)

# quadratic
# Interpola usando o valor mais próximo
quadratic = dados12.interpolate(method='quadratic')
plt.title('Interpolação Quadratic', fontweight='bold')
plt.plot(quadratic.Hs)

# Interpolação com dados numéricos simples

# Criando um vetor no pandas. No pandas um "vetor" se chama Series e uma "matriz" se chama DataFrame

numeros = pd.Series(np.arange(1,11))

#numeros = np.arange(1,11)
print(numeros)

# atribuindo valores nan ao número 3 e 8
numeros[2] = np.nan
numeros[7] = np.nan

print(numeros)

# Interpolando com os diferentes métodos
numeros.interpolate(method='linear')

numeros.interpolate(method='pad')

numeros.interpolate(method='nearest')

numeros.interpolate(method='quadratic')

# Exemplo interpolação polinomial de ordem 2 (x**2)    (x**2+ax+b)
s = pd.Series([1,4,np.nan,16])
print(s)

s.interpolate(method='polynomial', order=2)

"""#### 5. Estatísticas

link de referência > https://realpython.com/python-statistics/#calculating-descriptive-statistics

##### Medidas de tendência central
"""

# Média

notas = [1, 5, np.nan, 9, 4]
print(notas)

np.mean(notas)

notas = [1, 5, np.nan, 9, 4]
print(notas)

# Média
np.nanmean(notas)

(1+5+9+4)/4

#Refazando a lista
notas = [1, 5, 8, 9, 4]
np.mean(notas)

# Média ponderada
np.average(notas, weights=[2, 0.5, 1.5, 4, 2])

# Média geométrica  (5, pois são 5 números)  

(1*5*8*9*4)**(1/5)

# Média geométrica  

statistics.geometric_mean(notas)

# Mediana  >> com a lista ordenada é o valor do meio

notas_s = sorted(notas)
print(notas_s)

# Mediana

statistics.median(notas)

# Moda >> Valor que mais se repete

notas2 = [1, 9, 8, 9, 4]

statistics.mode(notas2)

"""##### Medidas de variabilidade"""

notas

# Variância 

statistics.variance(notas)

# Desvio padrão

statistics.stdev(notas)
#np.std(notas)

# Desvio padrão é a raiz quadrada da variância

(statistics.variance(notas))**(1/2)

# Assimetria

scipy.stats.skew(notas, bias=False)

plt.hist(notas, bins=5)   
# é assimetrica negativa

# Curtose
# bias = False >> é corrigido para o bias estatístico
scipy.stats.kurtosis(notas, bias=False)

# Vamos ver as estatíticas aplicada aos nossos dados

print(dados_c)

# Comando que fornece várias estatísticas

scipy.stats.describe(dados_c.Hs, bias=False)

dados_new = dados_c.dropna()
print(dados_new)

# Descrevendo dados de Hs
dados_new.Hs.describe(percentiles=[0.05,.25, .5, .75, 0.90, 0.95, 0.99])

scipy.stats.describe(dados_new.Hs, bias=False)

# Verificando a assimetria positiva

plt.hist(dados_new.Hs)
plt.title('Histograma de Hs', fontweight='bold')

# Mais valores concentrados nas menores alturas significativas.

# Correlação

# Calcula o coeficiente de correlaçaõ de Pearson entre Hs e Tp, e o p-value

r, p = scipy.stats.pearsonr(dados_new.Hs, dados_new.Tp)

print('Coeficiente de correlação de Pearson =', r)
print('p-value =', p)

# p-value = probabilidade de significância
#

"""#### 6. Regressão Linear"""

# Abrindo dados com Hs e Wspd (vel do vento)

dados_onda = pd.read_csv(path+'dados\\'+arq_nome, sep=',', header = 0, index_col = 0, parse_dates = ['# Datetime'],
                   date_parser = lambda x: datetime.datetime.strptime(x ,"%Y-%m-%d %H:%M:%S"),
                   usecols = ['# Datetime','Wvht','Wspd'])

dados_onda.rename(columns={'Wvht': 'Hs'}, inplace = True)

# Completei para todo o período (início de 2011 ao fim de 2018)
datas = pd.date_range('2011-01-01 00:00:00', '2018-12-21 23:59:59', freq='H')

dados_onda = dados_onda.reindex(datas)

dados_onda = dados_onda.replace(-9999.00, np.nan)

dados_onda = dados_onda.dropna()

print(dados_onda)

# Gráfico de dispersão

plt.figure(figsize=(5,5))
plt.scatter(dados_onda.Hs, dados_onda.Wspd, marker='o', color='blue')
plt.title('Gráfico de dispersão', fontweight='bold')
plt.xlabel("Altura Significativa de Onda (m)")
plt.ylabel("Velocidade do Vento (m/s)")
plt.xlim(0,8,1)
plt.ylim(0,22,2)
plt.savefig(path+'figs\\grafico_dispersao.png')

r, p = scipy.stats.pearsonr(dados_onda.Hs, dados_onda.Wspd)

print('Coeficiente de correlação de Pearson =', r)
print('p-value =', p)

# Regressão linear

rl = scipy.stats.linregress(dados_onda.Hs, dados_onda.Wspd)
print(rl)

# Coeficientes de reta 
a = rl.slope
b = rl.intercept

print("a =", a)
print("b =", b)

"""##### Slope = a ; intercept = b
y = a*x + b

dados_onda.Wspd = a * dados_onda.Hs + b
"""

# Gráfico de dispersão

plt.figure(figsize=(5,5))
plt.scatter(dados_onda.Hs, dados_onda.Wspd, marker='o', color='blue', zorder=10)
plt.plot(dados_onda.Hs, dados_onda.Hs*a + b, '-k', zorder=20)
plt.title('Gráfico de dispersão', fontweight='bold')
plt.xlabel("Altura Significativa de Onda (m)")
plt.ylabel("Velocidade do Vento (m/s)")
plt.xlim(0,8,1)
plt.ylim(0,22,2)
plt.grid(zorder=0)
plt.savefig(path+'figs\\grafico_dispersao_regressao_linear.png')

# Exemplo simples com alta correlação

# criando vetores

x = np.array([2, 3, 4, 5, 6])
y = np.array([2**2, 3**2, 4**2, 5**2, 6**2])

y

r, p = scipy.stats.pearsonr(x, y)
print(r)

# Regressão linear

rl = scipy.stats.linregress(x, y)
print(rl)

# Coeficientes de reta 
a = rl.slope
b = rl.intercept

print("a =", int(a))
print("b =", int(b))

for i in range(len(x)):
    print((x[i]*a) + b)

print('x =', x)
print('y =', y)

# Gráfico de dispersão

plt.figure(figsize=(5,5))
plt.scatter(x, y, marker='o', color='red', zorder=10)
plt.plot(x, (x*a) + b, '-k', zorder=20)
plt.title('Gráfico de dispersão', fontweight='bold')
plt.xlabel("X")
plt.ylabel("Y")
plt.grid(zorder=0)
plt.savefig(path+'figs\\grafico_dispersao_regressao_linear_exemplo_simples.png')

